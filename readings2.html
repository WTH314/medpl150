<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Reading 2 Reflection</title>
</head>
<body>
  <h1>Reading 2 – Reflection on Nesrine Malik, <em>On AI slop</em></h1>

  <p>
    The article author, Malik, aims to convey to the viewer that AI is undermining human perspectives by creating a world that obscures reality.  They have two types of separate readilies online, one is real and the other is AI-generated. This “slop includes everything from silly cartoons to dangerous political fantasies. And some examples that Malik gives, like “the white house account on X jumped on a trend of creating images in Studio Ghibli style and posts an image of a Dominican woman in tears as she is arrested by the immigration and Customs Enforcement (ICE).” The examples demonstrate that even the government has utilized AI to create propaganda, thereby gaining more support on its side. The problem with AI is that the events it creates can be fake, leading people to misleading information about what is actually happening. This is why people need to double-check their information before drawing their own conclusions.

  </p>
  
  <P>The content that is created by AI can sometimes be hard to know if the information that people send out online is actually real. A social media app example is AI slop that is in WhatsApp, where people can send an AI image to a friend that looks real. The author gives a personal example in which an elderly relative thought a message sent by a friend about the war was real because the image and video looked too real to be fake. AI will mostly affect the elderly or people who don’t know how to use technology because of their lack of understanding of social media and the internet. AI has built-in bias, which can promote an over-the-top different worldview because AI absorbed from the old internet data, which can create old-fashioned thinking, which can make people question that people ask the AI will receive one-sided answers, which can make it unreliable to provide resource-proven answers.

  </P>

  </p>And the worst part is that the big tech companies don’t care about whether the AI gives out fake information; they only care about the amount of money they can earn from the people using their tech. An example that the author uses is that Facebook promotes the use of AI slop because it is an easy and cheap way to get people to engage with its content on the Facebook page. This author's point is that AI can cause people to feel numb and confused when they see the AI's work, because their brains cannot distinguish between real and fake images, which can be unsettling. After all, it will make it hard to know whether the information they are getting is the real thing or a fake. Also, the author wrote the article to warn people not to ignore the real-world problems because it will hard to allow to people to understand the problem that is happen is real or fake after all the AI have create information which lead people think the problem is fix but is actually did’t get find so it best to look over the AI work or look at more information online you will not drew one idea just by look at one image you need to have more information to show that thing in the image did happen and not something that is made up the AI.



  </p>
  

  <p><a href="readings.html">Back to Readings</a></p>
  <p><a href="index.html">Back to Homepage</a></p>
</body>
</html>
